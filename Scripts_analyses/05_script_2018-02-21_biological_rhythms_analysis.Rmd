---
title: "2018-02-21_analyzing_larger_prelim_dataset"
output: 
  html_document: 
    highlight: espresso
    theme: spacelab
    toc: yes
---

# Load Libraries
```{r}
library(ggplot2) #plotting
library(data.table) # faster way of reading in data sets
#library(plyr) # manipualte data
library(lubridate) # to manipualte time
library(pracma) ## using this package for time series analysis,mainly the findpeaks function 
library(dplyr)
```


# Data Wrangling 

## Load data and get some summary stats. How many unique IDs in this sample data set? 

```{r}
#dat<-fread("MergeComplete.csv")
dat<-fread("../Data/04_2018-04-19_unique_ID_trikinetics_behavioral_counts.csv")

str(dat)# structure

dim(dat) # dimensions

# how many unique ids and how many records they have
rec<-dat%>%
  group_by(uniqueID)%>%
  summarise(counts=length(uniqueID))
#rec<-ddply(dat,.(uniqueID),summarize,counts=length(uniqueID))
dim(rec);rec

##there are 406 individuals!

##converting time to hours
time.conv<-lubridate::hms(dat$time) # convert to time object
dat$time2<-lubridate::hour(time.conv)+lubridate::minute(time.conv)/60+lubridate::second(time.conv)/3600+0.0001#need to add a small value so that there are no 0 hour values and they get counted into the 15 min bin
head(dat$time2)


dim(subset(dat,time2==0))
#fwrite(dat,"2018-02-23_datamanipu_check.csv")
```

## Binning based on a set of time intervals

### 15 minute bins 
```{r}
bins15=c(paste0(rep(c(paste0(0,0:9),10:23), each=4),":", c("00",15,30,45))[-1],"24:00") ## set bin categories within a day
bins15

##create a vector of bin categories that matches the dataset
dat$bins15=cut(dat$time2,breaks=seq(0,24,.25),labels=bins15)

##checking to see if there are NAs
head(dat,300)
#dat[235,14:15]
#dat[235,1:10]
```

### SUmming counts based on bins 

**For each unique id, date, experiment, and bin15, sum the counts for these subsets**

```{r}
#dat.sum.counts<-ddply(dat,.(uniqueID,date,experiment,bins15),summarize,counts15=sum(counts)) # timing start 11:35 AM ...even past 1:35PM...2:39PM
#dat$uniqueID<-as.factor(dat$uniqueID)
#dat$date<-as.factor(dat$date)
#dat$experiment<-as.factor(dat$experiment)
#dat$bins15<-as.character(dat$bins15)
dat.sum.counts<-dat %>% 
  dplyr::group_by(uniqueID,date,experiment,bins15)%>%
  dplyr::summarise(counts15=sum(counts))

dim(dat.sum.counts)
str(dat.sum.counts)



##checking if the manipulations are what I expect them to be. Are the same number of individuals retained? How many are in entrainment, how many in free run? 
rec.sum15<-dat.sum.counts%>%
  group_by(uniqueID,experiment)%>%
  summarise(length=length(bins15))


dim(rec.sum15)
treatment.table<-table(rec.sum15[,1:2]);treatment.table
treatment.table<-data.frame(cbind(treatment.table[,1],treatment.table[,2]))
treatment.table$uniqueID<-rownames(treatment.table)
dim(table(rec.sum15[,1:2])) # ok checking for the same number of individuals are retained through all of these manipulations. You can also see that all of them have an entrainment, and some don't have a free run.   

```


### plotting out individuals  

```{r}
ggplot(dat.sum.count)

```


## Estimate Dominant Frequency with spectral analysis 


### Making a function to get top periodograms with spectral analysis
```{r spectral analysis function}
sa.an<-function(ts=counts15$counts15){
  sa1<-spectrum(ts,method=c("pgram","ar"),plot=FALSE,demean=TRUE,detrend=TRUE,tape=.2)
  spx<-sa1$freq
  spy<-2*sa1$spec
  pw<-data.frame(spx,spy)
  cc1<-pw[order(pw$spy,decreasing=TRUE),]
  cc2<-subset(cc1,spx<0.05)
  cc2$density<-density(cc2$spy,n=length(cc2$spy))$y
  cc2$t<-density(cc2$spy,n=length(cc2$spy))$x
  #cc<-findpeaks(cc2[,3],minpeakheight=1E-6)
  cc<-findpeaks(cc2[,1])
  cc2[order(cc2$density,decreasing=TRUE),]
  out<-1/cc2[cc[,2],][,1]/4
  #out<-1/cc2[cc[,2],][,1]/4/24
  return(out[1:4])
  ## hours 
  
  
}

sa.an<-function(ts=counts15$counts15){
  sa1<-spectrum(ts,method=c("pgram","ar"),plot=FALSE,demean=TRUE,detrend=TRUE,tape=.2)
  spx<-sa1$freq
  spy<-2*sa1$spec
  pw<-data.frame(spx,spy)
  cc<-head(pw[order(pw$spy,decreasing=TRUE),],4)
  return(1/cc[,1]/4)  ## hours 
  #return(1/cc[,1]/4/24)  ## days 
  
}
sa.an()
```

### Spectral analysis on a single case just to check function 

```{r eval=FALSE}
#take 10o20
test<-subset(dat.sum.counts,uniqueID=="10o20")
#ddply(test,.(experiment),function(sub) sa.an(sub$counts15))
test %>% 
  group_by(experiment)%>%select(experiment)%>%summarise(n=length(experiment))
  
  
test %>% 
  group_by(experiment)%>%
  summarise(V1=sa.an(ts=counts15)[1],V2=sa.an(ts=counts15)[2],V3=sa.an(ts=counts15)[3])

sa1<-spectrum(test$counts15,method=c("pgram","ar"),demean=TRUE,detrend=TRUE,tape=.2)
spx<-sa1$freq
spy<-2*sa1$spec
pw<-data.frame(spx,spy)
cc1<-pw[order(pw$spy,decreasing=TRUE),]
cc2<-subset(cc1,spx<0.05)
cc2$density<-density(cc2$spy,n=length(cc2$spy))$y
cc2$t<-density(cc2$spy,n=length(cc2$spy))$x
cc<-findpeaks(cc2[,1])
cc2[order(cc2$density,decreasing=TRUE),]
out<-1/cc2[cc[,2],][,1]/4
#out<-1/cc2[cc[,2],][,1]/4/24
out[1:4]
```


### Implementing function across whole dataset

```{r spectral analysis functin applied to whole dataset}

##subset the data that has both entrainment and free run 
dat.sum.count.treatment<-inner_join(dat.sum.counts,treatment.table,by="uniqueID")
#subsetting if the unique ID has X1 and X2 > 0. 
dsct.sub<-subset(dat.sum.count.treatment,X1>0 & X2 > 0)
dim(dat.sum.count.treatment)
dim(dsct.sub)
#how many individuals left? 
length(unique(dsct.sub$uniqueID)) # 159


###time manipulation, gotta re-order the dates
dsct.sub$dt<-paste(dsct.sub$date,dsct.sub$bins15)
dsct.order2<-dsct.sub%>%
  group_by(uniqueID,experiment)%>%
  arrange(date)%>%
  mutate(time=seq(1,length(bins15),1))
#dsct.order<-ddply(dsct.sub,.(uniqueID,experiment),transform,order(date))
#dsct.order2<-ddply(dsct.order,.(uniqueID),transform,time=seq(1,length(bins15),1))
length(unique(dsct.order2$uniqueID))


###fitting

#whole.sa.dat<-ddply(dsct.order2,.(uniqueID,experiment),function(sub) sa.an(sub$counts15))
whole.sa.dat<-dsct.order2%>%
  group_by(uniqueID,experiment)%>%
  summarise(V1=sa.an(ts=counts15)[1],V2=sa.an(ts=counts15)[2],V3=sa.an(ts=counts15)[3])
whole.sa.dat

#fwrite(whole.sa.dat,"whole.sa.dat.csv")
```

### Making some plots 

raw data actograms 

```{r}
ggplot(dsct.order2,aes(x=time,y=counts15,colour=experiment))+geom_line()+facet_wrap(~uniqueID,nrow=10,scales="free")


sub5b21<-subset(dsct.order2,uniqueID=="5b21")
ggplot(sub5b21,aes(x=time,y=counts15,colour=experiment))+geom_line()

dsct.order3<-dsct.order2%>%
  arrange(uniqueID,date)

ggplot(dsct.order3,aes(y=counts15,colour=experiment))+geom_line()+facet_wrap(~uniqueID,nrow=10,scales="free")


```



## Merge eclosion data with fitted period data 

```{r}
#read in eclosion data
ecl<-fread("../Data/2018-04-18_rhagoletis_masterdata_data_slice.csv")
str(ecl)

merg.dat<-inner_join(whole.sa.dat,ecl,by="uniqueID")
length(unique(merg.dat$uniqueID))

#ddply(merg.dat,.(Host,organism),summarize,counts=length(Host))
#ddply(merg.dat,.(Host,organism,experiment),summarize,mean=mean(V1),sd=sd(V1),n=length(Host))
merg.dat%>%
  group_by(Host,organism)%>%
  summarise(counts=length(Host))


merg.dat%>%
  group_by(Host,organism)%>%
  summarise(mean=mean(V1),sd=sd(V1),n=length(Host))
```

### Statistics Plots! Eclosion vs circ timing 


```{r stats}
merg.dat<-subset(merg.dat,V1<50)
merg.dat$circ<-apply(merg.dat[,3:6],1,function(x){mean(subset(x,x<30 & x > 20))})

#mod1<-lmer(eclosion_days~V1*experiment+(1|cohort_day),merg.dat)
#summary(mod1)

ggplot(merg.dat,aes(x=circ,y=eclosion_days,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")

ggplot(merg.dat,aes(x=paste(Host,organism),y=circ))+geom_boxplot()
summary(aov(circ~organism,data=merg.dat))


ggplot(merg.dat,aes(x=V1,y=eclosion_days,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")
```


#subset haw

```{r}
#haw<-subset(merg.dat,Host=="Haw")
haw<-merg.dat%>%
  filter(Host=="Haw")

mod<-aov(V1~organism*experiment+uniqueID,data=haw)
summary(mod)
ggplot(data=haw,aes(x=experiment,y=V1,fill=organism))+geom_boxplot()+ylim(0,30)+ylab("Dominant Activity Rhythm (hours)")

haw.free<-subset(haw,experiment=="free run")
mod10<-aov(V1~organism,data=haw.free)
summary(mod10)



haw.e<-subset(haw,experiment=="entrainment")
mod11<-aov(V1~organism,data=haw.e)
summary(mod11)

```

### subset apple

```{r}
apple<-subset(merg.dat,Host=="Apple")

ggplot(apple,aes(x=V1,y=eclosion_days))+geom_point()+stat_smooth(method="lm")+facet_grid(.~experiment,scales="free")
apmod<-lm(eclosion_days~V1*experiment,data=apple)
summary(apmod)
```

## Try discrete wavelet analysis


```{r}
library(wmtsa)

test

Jcirc <- floor(log2(round(24/.25)))
floor(log2(round(24/.25)))

#DJt_circ <- wavMRDSum(test$counts15,levels=Jcirc ,keep.smooth=FALSE, keep.details=TRUE,reflect=TRUE,wavelet="s12",xform="modwt")
DJt_circ <- wavMRDSum(test$counts15,levels=7 ,keep.smooth=FALSE, keep.details=TRUE,reflect=TRUE,wavelet="s12",xform="modwt")

DJt_circ
plot(DJt_circ,col=rgb(0,0,.5,.5),type="l")

###finding peaks
#library(pracma)
IBL<-data.frame(findpeaks(DJt_circ))
names(IBL)<-c("Height","mid_time","initial_time","final_time")
IBL
diff(IBL$mid_time)/4
#diff(IBL$mid_time)/24
#hist(diff(IBL$mid_time)/4/24)
hist(diff(IBL$mid_time)/4)
mean(diff(IBL$mid_time)/4)



plot(IBL$mid_time[-10]/4,diff(IBL$mid_time)/4)
lines(IBL$mid_time[-10]/4,diff(IBL$mid_time)/4)
```

## Creating discrete wavelet function to apply to a dataset

```{r}

globdwf<-function(vec=test$counts15,Jcirc=6){
  DJt_circ <- wavMRDSum(vec,levels=Jcirc ,keep.smooth=FALSE, keep.details=TRUE,reflect=TRUE,wavelet="s12",xform="modwt")
  IBL<-data.frame(findpeaks(DJt_circ))
  names(IBL)<-c("Height","mid_time","initial_time","final_time")
  return(mean(diff(IBL$mid_time)/4))
}

globdwf()


```


### Applying globdwf() function for whole dataset

```{r}
# sort data that enables estimation of circ rhythm 
nam.vec.exclude<-dsct.order2%>%
  group_by(uniqueID,experiment)%>%
  summarise(n=length(experiment))%>%
  filter(n<768)%>%
  select(uniqueID)
as.vector(nam.vec.exclude)

#v<-c("12b32","5b31","5w42","h2b12","h2r23","h4o4")
#data.table example

#par.dat<-dsct.order2%>%
 # filter(uniqueID!="12b32"&uniqueID!="5b31"&uniqueID!="5w42"&uniqueID!="h2b12"&uniqueID!="h4o4"&uniqueID!="h2r23")
par.dat<-dsct.order2%>%
  filter(!uniqueID%in%nam.vec.exclude$uniqueID)

dwf.fits<-par.dat%>%
  group_by(uniqueID,experiment)%>%
  summarise(circ=globdwf(vec=counts15,Jcirc=6),ult=globdwf(vec=counts15,Jcirc=4),int=globdwf(vec=counts15,Jcirc=5))



ggplot(dwf.fits,aes(y=int,x=experiment))+geom_boxplot()
ggplot(dwf.fits,aes(y=circ,x=experiment))+geom_boxplot()
ggplot(dwf.fits,aes(y=ult,x=experiment))+geom_boxplot()



```


### Merge dat sets 


```{r}

merg.dat2<-inner_join(dwf.fits,ecl,by="uniqueID")
length(unique(merg.dat2$uniqueID))


ggplot(data=merg.dat2,aes(x=circ,y=eclosion_days,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")

ggplot(data=merg.dat2,aes(x=int,y=eclosion_days,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")

ggplot(data=merg.dat2,aes(x=ult,y=eclosion_days,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")

```

# SessionINfo

```{r}
```
