---
title: "2018-02-21_analyzing_larger_prelim_dataset"
output: 
  html_document: 
    highlight: espresso
    theme: spacelab
    toc: yes
editor_options: 
  chunk_output_type: console
---

# Load Libraries
```{r}
library(ggplot2) #plotting
library(data.table) # faster way of reading in data sets
#library(plyr) # manipualte data
library(lubridate) # to manipualte time
library(pracma) ## using this package for time series analysis,mainly the findpeaks function 
library(dplyr)
```


# Data Wrangling 

## Load data and get some summary stats. How many unique IDs in this sample data set? 

```{r}
#dat<-fread("MergeComplete.csv")
dat<-fread("../Data/04_2018-04-19_unique_ID_trikinetics_behavioral_counts.csv")
dat$uniqueID<-as.vector(as.factor(dat$uniqueID))

str(dat)# structure

dim(dat) # dimensions

# how many unique ids and how many records they have
rec<-dat%>%
  dplyr::group_by(uniqueID)%>%
  dplyr::summarise(counts=length(uniqueID))
#rec<-ddply(dat,.(uniqueID),summarize,counts=length(uniqueID))
dim(rec);rec

##there are 406 individuals!

##converting time to hours
time.conv<-lubridate::hms(dat$time) # convert to time object
dat$time2<-lubridate::hour(time.conv)+lubridate::minute(time.conv)/60+lubridate::second(time.conv)/3600+0.0001#need to add a small value so that there are no 0 hour values and they get counted into the 15 min bin
head(dat$time2)


dim(subset(dat,time2==0))
#fwrite(dat,"2018-02-23_datamanipu_check.csv")
```

## Binning based on a set of time intervals

### 15 minute bins 
```{r}
bins15=c(paste0(rep(c(paste0(0,0:9),10:23), each=4),":", c("00",15,30,45))[-1],"24:00") ## set bin categories within a day
bins15

##create a vector of bin categories that matches the dataset
dat$bins15=cut(dat$time2,breaks=seq(0,24,.25),labels=bins15)

##checking to see if there are NAs
head(dat,300)
#dat[235,14:15]
#dat[235,1:10]
```

### SUmming counts based on bins 

**For each unique id, date, experiment, and bin15, sum the counts for these subsets**

```{r}
#dat.sum.counts<-ddply(dat,.(uniqueID,date,experiment,bins15),summarize,counts15=sum(counts)) # timing start 11:35 AM ...even past 1:35PM...2:39PM
#dat$uniqueID<-as.factor(dat$uniqueID)
#dat$date<-as.factor(dat$date)
#dat$experiment<-as.factor(dat$experiment)
#dat$bins15<-as.character(dat$bins15)
dat.sum.counts<-dat %>% 
  dplyr::group_by(uniqueID,date,experiment,bins15)%>%
  dplyr::summarise(counts15=sum(counts))

dim(dat.sum.counts)
str(dat.sum.counts)
length(unique(as.factor(dat.sum.counts$uniqueID)))
#summary(dat.sum.counts)


##checking if the manipulations are what I expect them to be. Are the same number of individuals retained? How many are in entrainment, how many in free run? 
rec.sum15<-dat.sum.counts%>%
  dplyr::group_by(uniqueID,experiment)%>%
  dplyr::summarise(length=length(bins15))


dim(rec.sum15)
treatment.table<-table(rec.sum15[,1:2]);treatment.table
treatment.table<-data.frame(cbind(treatment.table[,1],treatment.table[,2]))
treatment.table$uniqueID<-rownames(treatment.table)
dim(table(rec.sum15[,1:2])) # ok checking for the same number of individuals are retained through all of these manipulations. You can also see that all of them have an entrainment, and some don't have a free run.   

```

## Estimate Dominant Frequency with spectral analysis 


### Making a function to get top periodograms with spectral analysis
```{r spectral analysis function}
sa.an<-function(ts=counts15$counts15){
  sa1<-spectrum(ts,method=c("pgram","ar"),plot=FALSE,demean=TRUE,detrend=TRUE,tape=.2)
  spx<-sa1$freq
  spy<-2*sa1$spec
  pw<-data.frame(spx,spy)
  cc1<-pw[order(pw$spy,decreasing=TRUE),]
  cc2<-subset(cc1,spx<0.05)
  cc2$density<-density(cc2$spy,n=length(cc2$spy))$y
  cc2$t<-density(cc2$spy,n=length(cc2$spy))$x
  #cc<-findpeaks(cc2[,3],minpeakheight=1E-6)
  cc<-findpeaks(cc2[,1])
  cc2[order(cc2$density,decreasing=TRUE),]
  out<-1/cc2[cc[,2],][,1]/4
  #out<-1/cc2[cc[,2],][,1]/4/24
  return(out[1:4])
  ## hours 
  
  
}

sa.an<-function(ts=counts15$counts15){
  sa1<-spectrum(ts,method=c("pgram","ar"),plot=FALSE,demean=TRUE,detrend=TRUE,tape=.2)
  spx<-sa1$freq
  spy<-2*sa1$spec
  pw<-data.frame(spx,spy)
  cc<-head(pw[order(pw$spy,decreasing=TRUE),],4)
  return(1/cc[,1]/4)  ## hours 
  #return(1/cc[,1]/4/24)  ## days 
  
}
sa.an()
```

### Spectral analysis on a single case just to check function 

```{r eval=FALSE}
#take 10o20
test<-subset(dat.sum.counts,uniqueID=="10o20")

#plot it just to look at it and I need for a psoter
test$n<-seq(1,length(test$uniqueID),length.out = length(test$uniqueID))
test$days<-test$n/96

ggplot(test,aes(x=days,y=counts15,colour=experiment))+geom_line()+xlab("Days")+ylab("Activity Counts")+scale_color_manual(values=c("blue","black"))+T


#ddply(test,.(experiment),function(sub) sa.an(sub$counts15))


test %>% 
  group_by(experiment)%>%select(experiment)%>%summarise(n=length(experiment))
  
  
test %>% 
  group_by(experiment)%>%
  summarise(V1=sa.an(ts=counts15)[1],V2=sa.an(ts=counts15)[2],V3=sa.an(ts=counts15)[3])

sa1<-spectrum(test$counts15,method=c("pgram","ar"),demean=TRUE,detrend=TRUE,tape=.2)
spx<-sa1$freq
spy<-2*sa1$spec
pw<-data.frame(spx,spy)
cc1<-pw[order(pw$spy,decreasing=TRUE),]
cc2<-subset(cc1,spx<0.05)
cc2$density<-density(cc2$spy,n=length(cc2$spy))$y
cc2$t<-density(cc2$spy,n=length(cc2$spy))$x
cc<-findpeaks(cc2[,1])
cc2[order(cc2$density,decreasing=TRUE),]
out<-1/cc2[cc[,2],][,1]/4
#out<-1/cc2[cc[,2],][,1]/4/24
out[1:4]
```


### Implementing function across whole dataset

```{r spectral analysis functin applied to whole dataset}

##subset the data that has both entrainment and free run 
dat.sum.count.treatment<-inner_join(dat.sum.counts,treatment.table,by="uniqueID")
head(dat.sum.count.treatment)
#subsetting if the unique ID has X1 and X2 > 0. 
dsct.sub<-subset(dat.sum.count.treatment,X1>0 & X2 > 0)
#how many individuals left? 
length(unique(dsct.sub$uniqueID)) # 298


###time manipulation, gotta re-order the dates
dsct.sub$dt<-paste(dsct.sub$date,dsct.sub$bins15)
dsct.order2<-dsct.sub%>%
  dplyr::group_by(uniqueID,experiment)%>%
  dplyr::arrange(date)%>%
  dplyr::mutate(time=seq(1,length(bins15),1))
#dsct.order<-ddply(dsct.sub,.(uniqueID,experiment),transform,order(date))
#dsct.order2<-ddply(dsct.order,.(uniqueID),transform,time=seq(1,length(bins15),1))
length(unique(dsct.order2$uniqueID))


###fitting

#whole.sa.dat<-ddply(dsct.order2,.(uniqueID,experiment),function(sub) sa.an(sub$counts15))
whole.sa.dat<-dsct.order2%>%
  dplyr::group_by(uniqueID,experiment)%>%
  dplyr::summarise(V1=sa.an(ts=counts15)[1],V2=sa.an(ts=counts15)[2],V3=sa.an(ts=counts15)[3])
whole.sa.dat

#fwrite(whole.sa.dat,"whole.sa.dat.csv")
```

### Making some plots 

raw data actograms 

```{r}
#ggplot(dsct.order2,aes(x=time,y=counts15,colour=experiment))+geom_line()+facet_wrap(~uniqueID,nrow=10,scales="free")


#sub5b21<-subset(dsct.order2,uniqueID=="5b21")
#ggplot(sub5b21,aes(x=time,y=counts15,colour=experiment))+geom_line()

dsct.order3<-dsct.order2%>%
  arrange(uniqueID,date)

ggplot(dsct.order3,aes(y=counts15,colour=experiment))+geom_line()+facet_wrap(~uniqueID,nrow=10,scales="free")


```



## Merge eclosion data with fitted period data 

```{r}
#read in eclosion data
#ecl<-fread("../Data/2018-04-18_rhagoletis_masterdata_data_slice.csv")
ecl<-fread("05_master_dataset_eclosions_IDs.csv")
ecl<-ecl[,-1]
str(ecl)

merg.dat<-inner_join(whole.sa.dat,ecl,by="uniqueID")
length(unique(merg.dat$uniqueID))

#ddply(merg.dat,.(Host,organism),summarize,counts=length(Host))
#ddply(merg.dat,.(Host,organism,experiment),summarize,mean=mean(V1),sd=sd(V1),n=length(Host))
merg.dat%>%
  dplyr::group_by(Host,treatment,organism)%>%
  dplyr::summarise(counts=length(Host))%>%
  knitr::kable()

#merg.dat%>%
#  group_by(Host,organism)%>%
 # summarise(mean=mean(V1),sd=sd(V1),n=length(Host))
```

### Filter out unique IDs that have not accounted for the monitor 6 switch

```{r}
#list of samples that need to be filtered out 

list<-c("2b15","19r23","4o72","18w11","13r12","10w6","11o16","12o67","11o40","11w11","18w22","12w53")

merg.dat%>%
  filter(uniqueID %in% list)
#none match
#s11w5<-subset(dsct.order2,uniqueID=="11w5")
#ggplot(s11w5,aes(x=time,y=counts15,colour=experiment))+geom_line()+
```


### Statistics Plots! Eclosion vs circ timing 


```{r stats}
merg.dat<-subset(merg.dat,V1<50)
merg.dat$circ<-apply(merg.dat[,3:6],1,function(x){mean(subset(x,x<30 & x > 20))})

#mod1<-lmer(eclosion_days~V1*experiment+(1|cohort_day),merg.dat)
#summary(mod1)

ggplot(merg.dat,aes(x=circ,y=new.eclosions,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")

ggplot(merg.dat,aes(x=paste(Host,organism),y=circ))+geom_boxplot()
summary(aov(circ~organism,data=merg.dat))


ggplot(merg.dat,aes(x=V1,y=new.eclosions,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")

merg.dat%>%
  dplyr::group_by(Host,organism,experiment)%>%
  dplyr::summarise(n=length(Host))%>%
  knitr::kable()
```


### Subset flies

```{r}
flies.hosts<-merg.dat%>%
  filter(organism=="fly")#
  
summary(aov(new.eclosions~circ*treatment*Host,data=flies.hosts))  

flies.hosts2<-merg.dat%>%
  filter(organism=="fly"&treatment=="SO")#
  
summary(aov(new.eclosions~circ*Host,data=flies.hosts))  

ggplot(flies.hosts2,aes(y=new.eclosions,x=circ))+geom_point()+stat_smooth()

```

#subset haw

### Testing effect of experiment and organisms on biological rhythms

```{r}
#haw<-subset(merg.dat,Host=="Haw")
haw<-merg.dat%>%
  filter(Host=="Haw")

mod<-aov(V1~organism*experiment+uniqueID,data=haw)
summary(mod)
ggplot(data=haw,aes(x=experiment,y=V1,fill=organism))+geom_boxplot()+ylim(0,30)+ylab("Dominant \nActivity Rhythm (hours)")#+T

#ggplot(data=haw,aes(x=experiment,y=V1,group=uniqueID,colour=organism))+geom_point(size=3)+geom_line()+ylim(0,30)+ylab("Dominant \nActivity Rhythm (hours)")



haw%>%
  dplyr::group_by(experiment,organism)%>%
  dplyr::summarise(n=length(experiment))


haw.free<-subset(haw,experiment=="free run")
mod10<-aov(V1~organism,data=haw.free)
summary(mod10)

#ggplot(haw.free,aes(x=V1,y=new.eclosions,colour=organism))+geom_point()+stat_smooth(method="lm")


haw.e<-subset(haw,experiment=="entrainment")
mod11<-aov(V1~organism,data=haw.e)
summary(mod11)

#ggplot(haw.e,aes(x=organism,y=V1))+geom_boxplot()

```

### subset apple

```{r}
apple<-subset(merg.dat,Host=="Apple")

ggplot(apple,aes(x=V1,y=eclosion_days))+geom_point()+stat_smooth(method="lm")+facet_grid(.~experiment,scales="free")
apmod<-lm(eclosion_days~V1*experiment,data=apple)
summary(apmod)
```

## Try discrete wavelet analysis


```{r}
library(wmtsa)

test

Jcirc <- floor(log2(round(24/.25)))
floor(log2(round(24/.25)))

#DJt_circ <- wavMRDSum(test$counts15,levels=Jcirc ,keep.smooth=FALSE, keep.details=TRUE,reflect=TRUE,wavelet="s12",xform="modwt")
DJt_circ <- wavMRDSum(test$counts15,levels=7 ,keep.smooth=FALSE, keep.details=TRUE,reflect=TRUE,wavelet="s12",xform="modwt")

DJt_circ
plot(DJt_circ,col=rgb(0,0,.5,.5),type="l")

###finding peaks
#library(pracma)
IBL<-data.frame(findpeaks(DJt_circ))
names(IBL)<-c("Height","mid_time","initial_time","final_time")
IBL
diff(IBL$mid_time)/4
#diff(IBL$mid_time)/24
#hist(diff(IBL$mid_time)/4/24)
hist(diff(IBL$mid_time)/4)
mean(diff(IBL$mid_time)/4)



plot(IBL$mid_time[-10]/4,diff(IBL$mid_time)/4)
lines(IBL$mid_time[-10]/4,diff(IBL$mid_time)/4)
```

## Creating discrete wavelet function to apply to a dataset

```{r}

globdwf<-function(vec=test$counts15,Jcirc=6){
  DJt_circ <- wavMRDSum(vec,levels=Jcirc ,keep.smooth=FALSE, keep.details=TRUE,reflect=TRUE,wavelet="s12",xform="modwt")
  IBL<-data.frame(findpeaks(DJt_circ))
  names(IBL)<-c("Height","mid_time","initial_time","final_time")
  return(mean(diff(IBL$mid_time)/4))
}

globdwf()


```


### Applying globdwf() function for whole dataset

```{r}
# sort data that enables estimation of circ rhythm 
nam.vec.exclude<-dsct.order2%>%
  dplyr::group_by(uniqueID,experiment)%>%
  dplyr::summarise(n=length(experiment))%>%
  dplyr::filter(n<768)%>%
  dplyr::select(uniqueID)
as.vector(nam.vec.exclude)

#v<-c("12b32","5b31","5w42","h2b12","h2r23","h4o4")
#data.table example

#par.dat<-dsct.order2%>%
 # filter(uniqueID!="12b32"&uniqueID!="5b31"&uniqueID!="5w42"&uniqueID!="h2b12"&uniqueID!="h4o4"&uniqueID!="h2r23")
par.dat<-dsct.order2%>%
  dplyr::filter(!uniqueID%in%nam.vec.exclude$uniqueID)

#dwf.fits<-par.dat%>%
  #dplyr::group_by(uniqueID,experiment)%>%
 # dplyr::summarise(circ=globdwf(vec=counts15,Jcirc=6),ult=globdwf(vec=counts15,Jcirc=4),int=globdw#f(vec=counts15,Jcirc=5),up=globdwf(vec=counts15,Jcirc=7))


dwf.fits<-par.dat%>%
  dplyr::group_by(uniqueID,experiment)%>%
  dplyr::summarise(circ=globdwf(vec=counts15,Jcirc=6),ult=globdwf(vec=counts15,Jcirc=4),int=globdwf(vec=counts15,Jcirc=5))


names(dwf.fits)

ggplot(dwf.fits,aes(y=int,x=experiment))+geom_boxplot()
ggplot(dwf.fits,aes(y=circ,x=experiment))+geom_boxplot()
ggplot(dwf.fits,aes(y=ult,x=experiment))+geom_boxplot()



```


### Merge dat sets 


```{r}

merg.dat2<-inner_join(dwf.fits,ecl,by="uniqueID")
length(unique(merg.dat2$uniqueID))

#numbers
merg.dat2%>%
  dplyr::group_by(Host,organism,experiment,treatment)%>%
  dplyr::summarise(n=length(Host))

### relationship with eclosion
ggplot(data=merg.dat2,aes(x=circ,y=eclosion_days,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")

ggplot(data=merg.dat2,aes(x=int,y=eclosion_days,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")

ggplot(data=merg.dat2,aes(x=ult,y=eclosion_days,colour=paste(Host,organism)))+geom_point()+stat_smooth(method="lm")


#looking at sample sizes
merg.dat2%>%
  group_by(Host,organism,treatment)%>%
  summarise(n=length(Host))

##exploring ultradian filter
ggplot(data=merg.dat2,aes(y=ult,x=Host,colour=organism))+geom_boxplot()+facet_grid(treatment~experiment,scale="free")

RT.haw<-merg.dat2%>%
  filter(treatment=="RT"&Host=="Haw")

summary(aov(ult~experiment*organism+uniqueID,data=RT.haw))

# ultradian
ggplot(data=merg.dat2,aes(y=circ,x=Host,colour=organism))+geom_boxplot()+facet_grid(treatment~experiment)

summary(aov(circ~experiment*organism+uniqueID,data=RT.haw))

#high level
ggplot(data=merg.dat2,aes(y=int,x=Host,colour=organism))+geom_boxplot()+facet_grid(treatment~experiment)

summary(aov(int~experiment*organism+uniqueID,data=RT.haw))


#
#dim(merg.dat2)
merg.dat2.SO<-merg.dat2%>%
  filter(treatment=="SO")

ggplot(merg.dat2.SO,aes(y=circ,x=experiment,colour=Host))+geom_boxplot()
ggplot(merg.dat2.SO,aes(y=circ,x=experiment,colour=Host,group=uniqueID))+geom_line()+geom_point()

library(lme4)
library(lmerTest)
m1<-lmer(circ~experiment*Host+(1|uniqueID),data=merg.dat2.SO)
summary(m1)

m2<-lmer(ult~experiment*Host+(1|uniqueID),data=merg.dat2.SO)
summary(m2)
plot(m2)


ggplot(merg.dat2.SO,aes(y=ult,x=experiment,colour=Host))+geom_boxplot()
```


### Subset out a few unique ids and plot them 

h4013 sample

```{r h4o13 sample}
###bneed to change h4o4

h4o13<-dsct.order3%>%
  filter(uniqueID=="h4o13")

h4o13$hm<-hour(hm(h4o13$bins15))+minute(hm(h4o13$bins15))/60

# days stacked
ggplot(h4o13,aes(x=hm,y=counts15,colour=experiment))+geom_line()+facet_grid(date~.,scale="free")+geom_vline(xintercept=c(6,20))

# phase shift
#ggplot(h4o13,aes(x=time,y=counts15,colour=experiment))+geom_line()+facet_grid(date~.,scale="free")#+geom_vline(xintercept=c(6,20))

# lets pot by days
#bin by days

h4o13.days<-h4o13%>%
  dplyr::group_by(experiment,date)%>%
  dplyr::summarise(day.counts=sum(counts15))

ggplot(h4o13.days,aes(x=date,y=day.counts,group=experiment,colour=experiment))+geom_line()+geom_point()

#lets see how many days there are 
h4o13.days%>%
  dplyr::group_by(experiment)%>%
  dplyr::summarise(n=length(experiment))

```

h4o13 analyses

```{r single analyses on h4o13}
#spectral density analysis

#15 min bins
estim<-h4o13%>%
  dplyr::group_by(experiment)%>%
  dplyr::summarise(V1=sa.an(ts=counts15)[1],V2=sa.an(ts=counts15)[2],V3=sa.an(ts=counts15)[3])
estim

#bin by days
estim.day<-h4o13.days%>%
  dplyr::group_by(experiment)%>%
  dplyr::summarise(V1=sa.an(ts=day.counts)[1]*4,V2=sa.an(ts=day.counts)[2]*4,V3=sa.an(ts=day.counts)[3]*4)
estim.day

#wavelet analysis 
estim2<-h4o13%>%
  dplyr::group_by(experiment)%>%
  #dplyr::filter(experiment=="free run")%>%
  dplyr::summarise(circ=globdwf(vec=counts15,Jcirc=6),ult=globdwf(vec=counts15,Jcirc=4),int=globdwf(vec=counts15,Jcirc=5))#,hi=globdwf(vec=counts15,Jcirc=7)
estim2

#lomb-scargle analysis
#install.packages("lomb")
library(lomb)
a<-lsp(h4o13$counts15,times=h4o13$time/4,type="period",from=5,to=100)
summary(a)
a$peak
a$peak.at[1]
##grabbing the significant peaks
per<-data.frame(power=a$power,time=a$scanned)
per%>%filter(power>a$sig.level)


###estimating period for different experiments
#15 min bins
lsa<-h4o13%>%
  dplyr::group_by(experiment)%>%
  dplyr::do(dp=lsp(.$counts15,times=.$time/4,type="period",from=5,to=100)$peak.at[1])

lsa$dp<-lsa%>%
  dplyr::rowwise()%>%
  dplyr::select("dp")%>%
  unlist()
lsa

#day bins
h4o13.days<-h4o13.days%>%
  dplyr::group_by(experiment)%>%
  dplyr::mutate(.,time=seq(1,length(experiment),1))

lsa.d<-h4o13.days%>%
  dplyr::group_by(experiment)%>%
  dplyr::do(dp=lsp(.$day.counts,times=.$time,type="period",from=3,to=50)$peak.at[1])

lsa.d$dp<-lsa.d%>%
  dplyr::rowwise()%>%
  dplyr::select("dp")%>%
  unlist()
lsa.d


#randlsp(repeats=50,h4o13$counts15,times=h4o13$time,type="period")

#periodograms
library(TSA)

pergram<-periodogram(h4o13$counts15,xlim=c(0,.05))
str(pergram)

per


install.packages('devtools')
devtools::install_github('hugheylab/tipa')
library('tipa')

?tipaPhaseRef
```

# SessionINfo

```{r}
```
